{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8513f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "from sklearn.svm import LinearSVC\n",
    "from skimage import feature\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e71af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... category : black widow\n",
      "loaded category:black widow successfully\n",
      "loading... category : captain america\n",
      "loaded category:captain america successfully\n",
      "loading... category : doctor strange\n",
      "loaded category:doctor strange successfully\n",
      "loading... category : hulk\n",
      "loaded category:hulk successfully\n",
      "loading... category : ironman\n",
      "loaded category:ironman successfully\n",
      "loading... category : loki\n",
      "loaded category:loki successfully\n",
      "loading... category : spider-man\n",
      "loaded category:spider-man successfully\n",
      "loading... category : thanos\n",
      "loaded category:thanos successfully\n"
     ]
    }
   ],
   "source": [
    "train_image_paths = []\n",
    "train_labels = []\n",
    "# get all the image folder paths\n",
    "Categories=['black widow', 'captain america', 'doctor strange', 'hulk', 'ironman', 'loki', 'spider-man', 'thanos']\n",
    "datadir='dataset\\\\train' \n",
    "\n",
    "for i in Categories:\n",
    "    \n",
    "    print(f'loading... category : {i}')\n",
    "    path=os.path.join(datadir,i)\n",
    "    for img in os.listdir(path):\n",
    "        train_image_paths.append(os.path.join(path,img))\n",
    "        train_labels.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a42ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading... category : black widow\n",
      "loaded category:black widow successfully\n",
      "loading... category : captain america\n",
      "loaded category:captain america successfully\n",
      "loading... category : doctor strange\n",
      "loaded category:doctor strange successfully\n",
      "loading... category : hulk\n",
      "loaded category:hulk successfully\n",
      "loading... category : ironman\n",
      "loaded category:ironman successfully\n",
      "loading... category : loki\n",
      "loaded category:loki successfully\n",
      "loading... category : spider-man\n",
      "loaded category:spider-man successfully\n",
      "loading... category : thanos\n",
      "loaded category:thanos successfully\n"
     ]
    }
   ],
   "source": [
    "test_image_paths = []\n",
    "test_labels = []\n",
    "# get all the image folder paths\n",
    "Categories=['black widow', 'captain america', 'doctor strange', 'hulk', 'ironman', 'loki', 'spider-man', 'thanos']\n",
    "datadir='dataset\\\\test' \n",
    "\n",
    "for i in Categories:\n",
    "    \n",
    "    print(f'loading... category : {i}')\n",
    "    path=os.path.join(datadir,i)\n",
    "    for img in os.listdir(path):\n",
    "        test_image_paths.append(os.path.join(path,img))\n",
    "        test_labels.append(Categories.index(i))\n",
    "    print(f'loaded category:{i} successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f63eb061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1633663, 64)\n",
      "Training KMeans...\n",
      "Done\n",
      "Persisting codebook...\n",
      "Done\n",
      "Generating BOW features for training set...\n",
      "Train images: (2325, 150)\n",
      "Generating BOW features for test set...\n",
      "Test images: (451, 150)\n",
      "Training a linear SVM...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import cv2 as cv\n",
    "import joblib\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from lab3_utils import get_image_paths\n",
    "#from utils import *\n",
    "from utils import read_img\n",
    "\n",
    "\n",
    "DATA_PATH = 'dataset'\n",
    "IMAGE_CATEGORIES = ['black widow', 'captain america', 'doctor strange', 'hulk', 'ironman', 'loki', 'spider-man', 'thanos']\n",
    "BRISK_MAX_FEATURES = 300\n",
    "\n",
    "\n",
    "def build_codebook(image_paths, num_tokens=150):\n",
    "    brisk = cv.BRISK_create()\n",
    "    container = []\n",
    "    for image_path in image_paths:\n",
    "        img = read_img(image_path, mono=True)\n",
    "        keypoints, descriptors = brisk.detectAndCompute(img, None)\n",
    "        if descriptors is not None:\n",
    "            container.append(descriptors)\n",
    "    container = np.concatenate(container)\n",
    "    print(container.shape)\n",
    "    print('Training KMeans...')\n",
    "    kmeans = KMeans(n_clusters=num_tokens)\n",
    "    kmeans.fit(container)\n",
    "    print('Done')\n",
    "    return kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "def bag_of_words(image_paths, codebook):\n",
    "    brisk = cv.BRISK_create()\n",
    "    codebook_size = codebook.shape[0]\n",
    "    image_features = []\n",
    "    for image_path in image_paths:\n",
    "        img = read_img(image_path, mono=True)\n",
    "        keypoints, descriptors = brisk.detectAndCompute(img, None)\n",
    "        bow = np.zeros(codebook_size)\n",
    "        if descriptors is not None:\n",
    "            distances = cdist(descriptors, codebook)\n",
    "            for d in distances:\n",
    "                bow[np.argmin(d)] += 1\n",
    "        image_features.append(bow.reshape(1, codebook_size))\n",
    "    image_features = np.concatenate(image_features)\n",
    "    return image_features\n",
    "\n",
    "\n",
    "if os.path.exists('Saved_Models_SVM/codebook_BRISK.joblib'):\n",
    "    codebook = joblib.load('Saved_Models_SVM/codebook_BRISK.joblib')\n",
    "else:\n",
    "    codebook = build_codebook(train_image_paths)\n",
    "    print('Persisting codebook...')\n",
    "    joblib.dump(codebook, 'Saved_Models_SVM/codebook_BRISK.joblib')\n",
    "    print('Done')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "print('Generating BOW features for training set...')\n",
    "train_images = bag_of_words(train_image_paths, codebook)\n",
    "train_images_scaled = scaler.fit_transform(train_images)\n",
    "print('Train images:', train_images.shape)\n",
    "\n",
    "print('Generating BOW features for test set...')\n",
    "test_images = bag_of_words(test_image_paths, codebook)\n",
    "test_images_scaled = scaler.transform(test_images)\n",
    "print('Test images:', test_images.shape)\n",
    "\n",
    "if os.path.exists('Saved_Models_SVM/svm_bow_BRISK.joblib'):\n",
    "    print('Loading existing linear SVM model...')\n",
    "    svm = joblib.load('Saved_Models_SVM/svm_bow_BRISK.joblib')\n",
    "else:\n",
    "    print('Training a linear SVM...')\n",
    "    svm = SVC(gamma='scale')\n",
    "    svm.fit(train_images_scaled, train_labels)\n",
    "    joblib.dump(svm, 'Saved_Models_SVM/svm_bow_BRISK.joblib')\n",
    "print('Done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c9441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy of SVM with BOW features: 0.22394678492239467\n"
     ]
    }
   ],
   "source": [
    "test_predictions = svm.predict(test_images_scaled)\n",
    "accuracy = accuracy_score(test_labels, test_predictions)\n",
    "print('Classification accuracy of SVM with BOW features:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84d7a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20246804369346988"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(test_labels, test_predictions, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f094e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
